{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure no W&B logging will be performed\n",
    "# sys.argv += \"-log tb -name tst -task gru_repeat -reset 1 -state_size 64 -load_pretrained_model ../checkpoints/gru_64-70k.pth -var_analysis.no_input 1\".split(\" \")\n",
    "sys.argv += \"-log tb -name tst -task gru_repeat -reset 1 -state_size 64 -load_pretrained_model ../checkpoints/gru_64_with_input.pth -var_analysis.no_input 0\".split(\" \")\n",
    "# sys.argv += \"-log tb -name tst -task gru_repeat -reset 1 -state_size 64 -load_pretrained_model ../checkpoints/gru_no_r-100k.pth -var_analysis.no_input 0\".split(\" \")\n",
    "# sys.argv += \"-log tb -name tst -task gru_repeat -reset 1 -state_size 64 -load_pretrained_model save/gru_digit_store/checkpoint/model-70000.pth -var_analysis.no_input 1\".split(\" \")\n",
    "#\n",
    "# sys.argv += \"-log tb -name tst -task gru_repeat -reset 1 -state_size 64 -load_pretrained_model ../checkpoints/gru_no_z-100k.pth -var_analysis.no_input 0\".split(\" \")\n",
    "\n",
    "\n",
    "# Pretend we are in the main directory\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from main import initialize\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Note: checkpoints have all arguments saved\n",
    "helper, task = initialize()\n",
    "task.create_data_fetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "diter = iter(task.train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data = next(diter)\n",
    "data= task.prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_overwrite(force, var, i, newval):\n",
    "    if var in force:\n",
    "        return force[var][i]\n",
    "    return newval\n",
    "\n",
    "def gru_run(model: torch.nn.GRU, x: torch.Tensor, h: Optional[torch.Tensor], lengths: torch.Tensor,\n",
    "            force = {}):\n",
    "    assert model.num_layers == 1\n",
    "    wir, wiz, win = model.weight_ih_l0.chunk(3, dim=0)\n",
    "    whr, whz, whn = model.weight_hh_l0.chunk(3, dim=0)\n",
    "    bir, biz, bin = model.bias_ih_l0.chunk(3, dim=0)\n",
    "    bhr, bhz, bhn = model.bias_hh_l0.chunk(3, dim=0)\n",
    "\n",
    "    if h is None:\n",
    "        h = torch.zeros(x.shape[1], wir.shape[0], device=x.device, dtype=x.dtype)\n",
    "\n",
    "    rs = []\n",
    "    zs = []\n",
    "    ns = []\n",
    "    hs = []\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        r = torch.sigmoid(F.linear(x[i], wir, bir) + F.linear(h, whr, bhr))\n",
    "        z = torch.sigmoid(F.linear(x[i], wiz, biz) + F.linear(h, whz, bhz))\n",
    "        r = get_overwrite(force, \"r\", i, r)\n",
    "        z = get_overwrite(force, \"z\", i, z)\n",
    "        z = z.masked_fill((i >= lengths)[..., None], 1.0)\n",
    "        n = torch.tanh(F.linear(x[i], win, bin) + r * F.linear(h, whn, bhn))\n",
    "        n = get_overwrite(force, \"n\", i, n)\n",
    "        h = (1 - z) * n + z * h\n",
    "\n",
    "        zs.append(z)\n",
    "        hs.append(h)\n",
    "        rs.append(r)\n",
    "        ns.append(n)\n",
    "        # print(h.shape)\n",
    "        # out, state = model(x[i:i+1], h.unsqueeze(0))\n",
    "        # h = h.squeeze(0)\n",
    "        # hs.append(h)\n",
    "\n",
    "    return torch.stack(hs, dim=0), torch.stack(rs, dim=0), torch.stack(zs, dim=0), torch.stack(ns, dim=0)\n",
    "\n",
    "\n",
    "def encode_with_state(self, inp: torch.Tensor, in_len: torch.Tensor, force={}) -> torch.Tensor:\n",
    "    x = self.embedding(inp.long())\n",
    "\n",
    "    state = None\n",
    "\n",
    "    states, rs, zs, ns = gru_run(self.rnn, x, state, in_len, force)\n",
    "\n",
    "    return states[-1], (states, rs, zs, ns)\n",
    "\n",
    "def decode_with_state(self, encoded_state: torch.Tensor, outp: torch.Tensor, out_len: torch.Tensor, force={}) -> torch.Tensor:\n",
    "    if self.no_input:\n",
    "        outp = torch.full_like(outp, self.no_input_token)\n",
    "\n",
    "    x = F.pad(outp[:-1], (0, 0, 1, 0), value=self.sos_token)\n",
    "    x = self.embedding(x.long())\n",
    "\n",
    "    states, rs, zs, ns = gru_run(self.rnn, x, encoded_state, out_len, force)\n",
    "    return self.fc(states), (states, rs, zs, ns)\n",
    "\n",
    "task.model.encode_with_state = encode_with_state.__get__(task.model)\n",
    "task.model.decode_with_state = decode_with_state.__get__(task.model)\n",
    "\n",
    "gru_run_orig = gru_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def run_model(data, enc_force={}, dec_force={}):\n",
    "    task.set_eval()\n",
    "    with torch.no_grad():\n",
    "        state, enc_states = task.model.encode_with_state(data[\"in\"], data[\"in_len\"], force=enc_force)\n",
    "        out, dec_states = task.model.decode_with_state(state, data[\"out\"], data[\"out_len\"], force=dec_force)\n",
    "\n",
    "    return out, (enc_states, dec_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "out, states = run_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Verify if the network is repeating correctly\n",
    "ok_mask = (data[\"out\"] == out.argmax(dim=-1)) | (torch.arange(data[\"out\"].shape[0], device=out.device)[:, None] >= data[\"out_len\"][None])\n",
    "seq_ok = ok_mask.all(dim=0)\n",
    "seq_ok.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plot_states(data, state, bi=0):\n",
    "    enc_states, dec_states = state\n",
    "    # plt.figure()\n",
    "    enc_states = (s[:data[\"in_len\"][bi], bi] for s in enc_states)\n",
    "    dec_states = (s[:data[\"out_len\"][bi], bi] for s in dec_states)\n",
    "\n",
    "    states, rs, zs, ns = (torch.cat([es, ds], dim=0) for es, ds in zip(enc_states, dec_states))\n",
    "\n",
    "    in_data = data[\"in\"][:data[\"in_len\"][bi], bi]\n",
    "    out_data = data[\"out\"][:data[\"out_len\"][bi], bi]\n",
    "    in_data = task.train_set.in_vocabulary(in_data.cpu().numpy().tolist())\n",
    "    out_data = task.train_set.out_vocabulary(out_data.cpu().numpy().tolist())\n",
    "\n",
    "    ticks = range(len(in_data) + len(out_data)), in_data + [\"S\"] + out_data[:-1]\n",
    "\n",
    "    fig, axs = plt.subplots(2,2, figsize=(10, 10))\n",
    "    plt.axes(axs[0,0])\n",
    "    plt.title(\"h[t]\")\n",
    "    plt.imshow(states.T.cpu().numpy(), aspect=\"auto\", cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "    plt.xticks(*ticks)\n",
    "\n",
    "    plt.axes(axs[0,1])\n",
    "    plt.title(\"z[t]\")\n",
    "    plt.imshow(zs.T.cpu().numpy(), aspect=\"auto\", cmap=\"viridis\", vmin=0, vmax=1)\n",
    "    plt.xticks(*ticks)\n",
    "\n",
    "    plt.axes(axs[1,0])\n",
    "    plt.title(\"rs[t]\")\n",
    "    plt.imshow(rs.T.cpu().numpy(), aspect=\"auto\", cmap=\"viridis\", vmin=0, vmax=1)\n",
    "    plt.xticks(*ticks)\n",
    "\n",
    "    plt.axes(axs[1,1])\n",
    "    plt.title(\"ns[t]\")\n",
    "    plt.imshow(ns.T.cpu().numpy(), aspect=\"auto\", cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "    plt.xticks(*ticks)\n",
    "\n",
    "    # plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plot_states(data, states, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plot_states(data, states, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plot_states(data, states, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_input(input: str) -> torch.Tensor:\n",
    "    a = task.train_set.in_vocabulary(input)\n",
    "    inp = torch.tensor(a, device=helper.device).unsqueeze(1)\n",
    "    in_len = torch.tensor([len(a)], device=helper.device)\n",
    "\n",
    "    return inp, in_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def run_model_on_str(input: str, enc_force={}, dec_force={}):\n",
    "    inp, in_len = create_input(input)\n",
    "    data = {\"in\": inp, \"in_len\": in_len, \"out\": inp, \"out_len\": in_len}\n",
    "    out, states = run_model(data, enc_force, dec_force)\n",
    "\n",
    "    out = out.argmax(dim=-1).squeeze(1)\n",
    "    print(task.train_set.out_vocabulary(out.cpu().numpy()))\n",
    "    print((out==inp.squeeze(1)).int().cpu().numpy())\n",
    "\n",
    "    return plot_states(data, states), (data, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "run_model_on_str(\"a b 1 c a d f a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "run_model_on_str(\"4 c a f g 6 1 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"states\", exist_ok=True)\n",
    "for i in range(10):\n",
    "    seq = torch.randint(0, len(task.train_set.in_vocabulary), (8,))\n",
    "    inp = \" \".join(task.train_set.in_vocabulary(seq.cpu().numpy()))\n",
    "    fig, _ = run_model_on_str(inp)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"states/{i}.png\")\n",
    "    plt.close(fig)\n",
    "    del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "_, s1 = run_model_on_str(\"a b 1 c a d f a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "run_model_on_str(\"4 c a f g 6 1 3\", {\"z\":})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s1 = run_model_on_str(\"a c f d 1 g 3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s1 = run_model_on_str(\"a a a a a a a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s1 = run_model_on_str(\"a b 1 c a d f 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gate(data, state, bi=0):\n",
    "    enc_states, dec_states = state\n",
    "    # plt.figure()\n",
    "    enc_states = (s[:data[\"in_len\"][bi], bi] for s in enc_states)\n",
    "    dec_states = (s[:data[\"out_len\"][bi], bi] for s in dec_states)\n",
    "\n",
    "    states, rs, zs, ns = (torch.cat([es, ds], dim=0) for es, ds in zip(enc_states, dec_states))\n",
    "\n",
    "    in_data = data[\"in\"][:data[\"in_len\"][bi], bi]\n",
    "    out_data = data[\"out\"][:data[\"out_len\"][bi], bi]\n",
    "    in_data = task.train_set.in_vocabulary(in_data.cpu().numpy().tolist())\n",
    "    out_data = task.train_set.out_vocabulary(out_data.cpu().numpy().tolist())\n",
    "\n",
    "    ticks = range(len(in_data) + len(out_data)), in_data + [\"S\"] + out_data[:-1]\n",
    "\n",
    "    fig, axs = plt.subplots(1,1, figsize=[3.2, 3])\n",
    "    plt.axes(axs)\n",
    "    plt.title(\"$z_t$\")\n",
    "    plt.imshow(1-zs.T.cpu().numpy(), aspect=\"auto\", cmap=\"viridis\", vmin=0, vmax=1)\n",
    "    plt.xticks(*ticks)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"$i_t$\")\n",
    "    plt.ylabel(\"$z_t [j]$\")\n",
    "    plt.yticks([],[])\n",
    "\n",
    "    # plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_gate(*s1)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"gate.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
